{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"snake.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tcquh4zc16n5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594715701077,"user_tz":-330,"elapsed":31367,"user":{"displayName":"lokesh borawar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAAKnzXjS5gQRhuxNqdIFyNBjo_2g1Br6_9Ejaiw=s64","userId":"16328719347553687725"}},"outputId":"003c0875-569f-43d5-8f8c-083d491f9f00"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zFGkZ23lvcFu","colab_type":"code","colab":{}},"source":["import cv2 as cv\n","import random as r\n","import numpy as np\n","import os\n","from google.colab.patches import cv2_imshow\n","#{'up':0,'down':1,'left':2,'right':3}\n","def env():\n","  global img,s_x,s_y\n","  global dista_ce,reward\n","  dista_ce=np.inf\n","  reward=0\n","  s_x,s_y=10,10\n","  img=np.zeros((500,500,3),dtype='uint8')\n","  img[0:500,0:10,0]=255\n","  img[0:10,0:500,0]=255\n","  img[490:500,0:500,0]=255\n","  img[0:500,490:500,0]=255\n","  x1=r.randrange(100,400,10)\n","  y1=r.randrange(x1,400,10)\n","  x2=r.randrange(100,400,10)\n","  y2=r.randrange(x2,400,10)\n","  x3=r.randrange(100,400,10)\n","  y3=r.randrange(x3,400,10)\n","  x4=r.randrange(100,400,10)\n","  y4=r.randrange(x4,400,10)\n","  x5=r.randrange(100,400,10)\n","  y5=r.randrange(x5,400,10)\n","  x6=r.randrange(100,400,10)\n","  y6=r.randrange(x6,400,10)\n","  img[x1:y1,x2:y2,0]=255\n","  img[x3:y3,x4:y4,0]=255\n","  img[x5:y5,x6:y6,0]=255\n","env()\n","def snake(s_x=10,s_y=10):\n","    img[s_x:s_x+10,s_y:s_y+10,1]=255\n","    return s_x,s_y\n","def food():\n","    global f_x,f_y\n","    f_x=r.randrange(10,490,10)\n","    f_y=r.randrange(10,490,10)        \n","    while img[f_x,f_y,2]!=img[f_x,f_y,0] or img[f_x,f_y,2]!=img[f_x,f_y,1]:\n","        f_x=r.randrange(10,490,10)\n","        f_y=r.randrange(10,490,10)\n","    img[f_x:f_x+10,f_y:f_y+10,2]=255\n","    return f_x,f_y\n","snake()\n","food()\n","def act(action):\n","    global s_x,s_y\n","    global dista_ce,reward\n","    s_x,s_y=snake(s_x,s_y)\n","    state=cv.resize(img.copy(),(100,100))\n","    #reward=0\n","    continu=False\n","    if(action==0):\n","        img[s_x:s_x+10,s_y:s_y+10,1]=0\n","        s_x=s_x-10\n","    elif(action==1):\n","        img[s_x:s_x+10,s_y:s_y+10,1]=0\n","        s_x=s_x+10\n","    elif(action==2):\n","        img[s_x:s_x+10,s_y:s_y+10,1]=0\n","        s_y=s_y-10\n","    elif(action==3):\n","        img[s_x:s_x+10,s_y:s_y+10,1]=0\n","        s_y=s_y+10\n","    snake(s_x,s_y)\n","    distance=np.sqrt(((s_x-f_x)**2)+((s_y-f_y)**2))\n","    if distance<dista_ce:\n","        dista_ce=distance\n","        reward=0.9\n","    elif distance>dista_ce:\n","        dista_ce=distance\n","        reward=-0.9\n","    next_state=cv.resize(img.copy(),(100,100))\n","    if img[s_x,s_y,1]==img[s_x,s_y,2]:\n","        img[f_x:f_x+10,f_y:f_y+10,2]=0\n","        reward=3\n","        dista_ce=np.inf\n","        food()\n","    if img[s_x,s_y,1]==img[s_x,s_y,0]:\n","        reward=-3\n","        continu=True\n","    return state,action,next_state,reward,continu "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJzA33SPx4NY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590672344366,"user_tz":-330,"elapsed":2430,"user":{"displayName":"Lokesh Borawar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLtTnFl3DkW-CwcjXWNv24eRfz1gl8g9KQPdAm=s64","userId":"11815423595674017450"}},"outputId":"13c1b7cc-087a-49dd-bc1f-a15beeade299"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uUoLsD1-7ehA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1590672354751,"user_tz":-330,"elapsed":11426,"user":{"displayName":"Lokesh Borawar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLtTnFl3DkW-CwcjXWNv24eRfz1gl8g9KQPdAm=s64","userId":"11815423595674017450"}},"outputId":"c59ea7ef-db1f-47f0-f464-4c5cf32068f7"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","\n","input_width = 100\n","input_height = 100\n","input_channels = 3\n","conv_n_maps = [32, 64, 64]\n","conv_kernel_sizes = [9, 5, 3]\n","conv_kernel_strides = [4, 2, 1]\n","conv_paddings = ['VALID'] * 3\n","conv_activation = [tf.nn.relu] * 3\n","n_hidden_in = 8 * 8 * 64\n","n_hidden = 512\n","hidden_activation = tf.nn.relu\n","n_outputs = 4\n","he_init = tf.contrib.layers.variance_scaling_initializer()\n","def q_network(X_state, name):\n","    prev_layer = X_state\n","    with tf.variable_scope(name,reuse=tf.AUTO_REUSE) as scope:\n","        for n_maps, kernel_size, strides, padding, activation in zip(\n","            conv_n_maps, conv_kernel_sizes, conv_kernel_strides, conv_paddings,\n","            conv_activation):\n","            prev_layer = tf.layers.conv2d(prev_layer, filters=n_maps,\n","                                          kernel_size=kernel_size,\n","                                          strides=strides, padding=padding,\n","                                          activation=activation,\n","                                          kernel_initializer=he_init)\n","        flattened = tf.reshape(prev_layer, [-1, n_hidden_in])\n","        hidden = tf.layers.dense(flattened, n_hidden,\n","                                 activation=hidden_activation,\n","                                 kernel_initializer=he_init)\n","        outputs = tf.layers.dense(hidden, n_outputs, kernel_initializer=he_init)\n","    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n","                                       scope=scope.name)\n","    trainable_vars_by_name = {var.name[len(scope.name):]: var\n","                              for var in trainable_vars}\n","    return outputs, trainable_vars_by_name\n","X_state = tf.placeholder(tf.float32, shape=(None, input_height, input_width,input_channels))\n","online_q_values, online_vars = q_network(X_state, 'q_networks/online')\n","target_q_values, target_vars = q_network(X_state, 'q_networks/target')\n","copy_ops = [var.assign(online_vars[name]) for name, var in target_vars.items()]\n","copy_online_to_target = tf.group(*copy_ops)\n","learning_rate = 1e-3\n","momentum = 0.95\n","with tf.variable_scope('training',reuse=tf.AUTO_REUSE) as scope:\n","    X_action = tf.placeholder(tf.int32, shape=(None,))\n","    y = tf.placeholder(tf.float32, shape=(None, 1))\n","    Q_target = tf.reduce_sum(online_q_values * tf.one_hot(X_action, n_outputs),axis=1, keepdims=True)\n","    error = tf.abs(y - Q_target)\n","    loss = tf.reduce_mean(tf.square(error))\n","    global_step = tf.Variable(0, trainable=False, name='global_step')\n","    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum,use_nesterov=True)\n","    training_op = optimizer.minimize(loss, global_step=global_step)\n","init = tf.global_variables_initializer()\n","saver = tf.train.Saver()\n","class ReplayMemory(object):\n","    def __init__(self, maxlen):\n","        self.maxlen = maxlen\n","        self.buf = np.empty(shape=maxlen, dtype=np.object)\n","        self.index = 0\n","        self.length = 0\n","\n","    def append(self, data):\n","        self.buf[self.index] = data\n","        self.index += 1\n","        self.index %= self.maxlen\n","        self.length = min(self.length + 1, self.maxlen)\n","\n","    def sample(self, batch_size):\n","        return self.buf[np.random.randint(self.length, size=batch_size)]\n","replay_size = 100000\n","replay_memory = ReplayMemory(replay_size)\n","def sample_memories(batch_size):\n","    cols = [[], [], [], [], []]  # state, action, next_state, reward, continue\n","    for memory in replay_memory.sample(batch_size):\n","        for col, value in zip(cols, memory):\n","            col.append(value)\n","    cols = [np.array(col) for col in cols]\n","    return cols[0].reshape(-1,100,100,3), cols[1], cols[2].reshape(-1,100,100,3), cols[3].reshape(-1, 1),cols[4].reshape(-1, 1)\n","eps_min = 0.1\n","eps_max = 1.0\n","eps_decay_steps = 6000000\n","def epsilon_greedy(q_values, step):\n","    epsilon = max(eps_min,\n","                  eps_max - ((eps_max - eps_min) * (step / eps_decay_steps)))\n","    if np.random.random() < epsilon:\n","        return np.random.randint(n_outputs)\n","    return np.argmax(q_values)\n","def normalize(st,nst):\n","  return np.divide(st,255),np.divide(nst,255)\n","n_steps = 10000000\n","training_start = 10000\n","training_interval = 4\n","save_steps = 1000\n","copy_steps = 10000\n","discount_rate = 0.95\n","skip_start = 20\n","batch_size = 50\n","iteration = 0\n","done = True  # To reset the environment at the start.\n","loss_val = np.infty\n","game_length = 0\n","total_max_q = 0.0\n","mean_max_q = 0.0\n","checkpoint_path = \"/content/drive/My Drive/A_snake/snake_dqn\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-4-8d5eeb3b45d5>:28: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From <ipython-input-4-8d5eeb3b45d5>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SyzICPCSx526","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"error","timestamp":1590684796839,"user_tz":-330,"elapsed":12431504,"user":{"displayName":"Lokesh Borawar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLtTnFl3DkW-CwcjXWNv24eRfz1gl8g9KQPdAm=s64","userId":"11815423595674017450"}},"outputId":"384ca131-0297-4336-c7d9-f6ed18f292ab"},"source":["# Main training loop\n","\n","with tf.Session() as sess:\n","    if os.path.isfile(checkpoint_path + '.index'):\n","        saver.restore(sess, checkpoint_path)\n","    else:\n","        init.run()\n","        copy_online_to_target.run()\n","    while True:\n","        step = global_step.eval()\n","        if step >= n_steps:\n","            break\n","        iteration += 1\n","        print('\\rIteration {}\\tTraining step {}/{} ({:.1f})%\\tLoss {:5f}'\n","              '\\tMean Max-Q {:5f} gameLength:{} reward:{} '.format(\n","                  iteration, step, n_steps, 100 * step / n_steps, loss_val,\n","                  mean_max_q,game_length,reward),\n","              end='')\n","        if done:\n","          env()\n","          food()\n","          snake()\n","\n","        # Evaluate the next action for the agent.\n","        q_values = online_q_values.eval(\n","            feed_dict={X_state: np.divide(cv.resize(img,(100,100)).reshape(-1,100,100,3),255)})\n","        action = epsilon_greedy(q_values, step)\n","\n","        # The online DQN plays the game.\n","        state,action,next_state,reward,done=act(action)\n","\n","        # Save the result in the ReplayMemory.\n","        replay_memory.append((state,action,next_state,reward, not done))\n","        ####state = next_state\n","\n","        # Compute statistics which help us monitor how training is going.\n","        total_max_q += q_values.max()\n","        game_length += 1\n","        if done:\n","            mean_max_q = total_max_q / game_length\n","            total_max_q = 0.0\n","            game_length = 0\n","\n","        # Only train after the warmup rounds and only every few rounds.\n","        if iteration < training_start or iteration % training_interval != 0:\n","            continue\n","\n","        # Sample memories from the reply memory.\n","        X_state_val, X_action_val, X_next_state_val, rewards, continues = sample_memories(batch_size)\n","        X_state_val,X_next_state_val=normalize(X_state_val,X_next_state_val)\n","        next_q_values = target_q_values.eval(\n","            feed_dict={X_state: X_next_state_val})\n","        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n","        y_val = rewards + continues * discount_rate * max_next_q_values\n","\n","        # Train the online DQN.\n","        _, loss_val = sess.run([training_op, loss], feed_dict={\n","            X_state: X_state_val,\n","            X_action: X_action_val,\n","            y: y_val,\n","        })\n","\n","        # Regularly copy the online DQN to the target DQN.\n","        if step % copy_steps == 0:\n","            copy_online_to_target.run()\n","\n","        # Regularly save the model.\n","        if step and step % save_steps == 0:\n","            saver.save(sess, checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/drive/My Drive/A_snake/snake_dqn\n","Iteration 1155360\tTraining step 6486341/10000000 (64.9)%\tLoss 0.081136\tMean Max-Q 16.471025 gameLength:60 reward:0.9 "],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-15f7a780dc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mX_state_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_next_state_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_state_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_next_state_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         next_q_values = target_q_values.eval(\n\u001b[0;32m---> 52\u001b[0;31m             feed_dict={X_state: X_next_state_val})\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mmax_next_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontinues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiscount_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_next_q_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5407\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"FKkjJeT_zNxu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117},"executionInfo":{"status":"ok","timestamp":1590684875769,"user_tz":-330,"elapsed":75617,"user":{"displayName":"Lokesh Borawar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLtTnFl3DkW-CwcjXWNv24eRfz1gl8g9KQPdAm=s64","userId":"11815423595674017450"}},"outputId":"e729f6c1-226f-4608-dfb2-efadbcfa9e17"},"source":["from IPython.display import clear_output\n","done=True\n","video=cv.VideoWriter('snake.mp4',cv.VideoWriter_fourcc('m','p','4','v'),15,(100,100))\n","with tf.Session() as sess:\n","  saver.restore(sess,checkpoint_path)\n","  for gameLength in range(20):\n","    env()\n","    food()\n","    snake()\n","    for Length in range(200):\n","      clear_output(wait=True)\n","      if done:\n","        env()\n","        food()\n","        snake()\n","      q_values = online_q_values.eval(feed_dict={X_state: np.divide(cv.resize(img,(100,100)).reshape(-1,100,100,3),255)})\n","      action=np.argmax(q_values)\n","      state,_,next_state,reward,done=act(action)\n","      video.write(next_state)\n","      cv2_imshow(next_state)\n","video.release()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAABL0lEQVR4nO3bsQqDMBRAUS3+/y/boXRxaU9tMMI9k4NDuDzEEF2XZV/yncfVC7iT7X2xXrmKG9iXJosUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAtsn28xM5wVjTpPaLJAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAsUCxQLFAscCpWPscx4RHw5bVZIFTJ9KT/kk2bFlNFigWKBYoFigWKBYoFigWKBb4+zelr9fn0VvGa/YOTRb4+2T9ZtJd5kGTBYoFigUGPbPu8QxSTRYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWWOf8zXlOTRZ4An6FCdLSsLxOAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=100x100 at 0x7F88AF847860>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"mwO_RtIgIm2C","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxXkxR8id2Xq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}